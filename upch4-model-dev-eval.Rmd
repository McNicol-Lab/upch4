---
title: "UpCH4: Model Development and Evaluation"
author: "Gavin McNicol"
date: "2023-05-24"
output:
  tufte::tufte_html:
    css: notebook.css
    tufte_variant: "envisioned"
    highlight: pygments
link-citations: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(eval = TRUE)
```

## Purpose

Code for predictive model development and evaluation for upscaling wetland eddy covariance methane flux data from sites to the globe. The code takes pre-processed weekly mean eddy covariance flux tower from FLUXNET-CH4 v1.0 [(Delwiche et al. 2021)](http://dx.doi.org/10.5194/essd-13-3607-2021) and static and dynamic geospatial predictor datasets as input for a random forest model training pipeline, and outputs:

  1) a best-predictor set using forward spatial feature selection
  2) spatial cross validation metrics of model performance
  3) variable importance rankings

The final three sections output:

  4) simulated training datasets from Monte Carlo to propagate uncertainties
  5) representativeness products (dissimilarity and constituency maps)
  6) globally upscaled product evaluations
  
Manuscript Reference: *McNicol, G. Fluet-Chouinard, E. et al. Upscaling wetland methane emissions from the FLUXNET-CH4 eddy covariance network (UpCH4 v1.0): Model development, network assessment, and budget comparison. AGU Advances, Accepted, May 2023*

```{r echo = F, out.width='100%', fig.align='center', fig.cap="Figure 1. Full UpCH4 workflow"}
knitr::include_graphics("img/workflow-figure.pdf")
```


```{marginfigure}
For brevity, this notebook does not include data pre-processing and upscaling run HPC code which is available from the corresponding authors at request. 
```

## Libraries

```{r packages, echo = F}
library(tidyverse)
library(readxl)
library(skimr)
library(caret)
library(ranger)
library(RColorBrewer)
library(pdp)
source("code/ggplot_theme.R")
```


## Data

The eddy covariance data used in this study are publicly available as part of the FLUXNET-CH4 community product V1.0 at [fluxnet.org](https://fluxnet.org/data/fluxnet-ch4-community-product/). The FLUXNET-CH4 synthesis activity is introduced in [Knox et al. 2019](10.1175/BAMS-D-18-0268.1) along with a detailed description of the eddy covariance post-processing steps including methane flux (FCH4) uncertainties. The first full (V1.0) dataset release (FLUXNET-CH4, hereafter) is described for 81 sites and is used in a wetland seasonality analysis in [Delwiche et al. in review](10.5194/essd-2020-307). 

Details for this study:

  - **Data for this CH4 Upscaling Project were downloaded from [fluxnet.org](www.fluxnet.org) on Feb 22, 2021.**
  - Permission was received via email on Feb 22, 2021, to use *Tier 2 Data Policy* sites in this study (SE-St1 and RU-Vrk; PI Thomas Friborg)
  - FLUXNET-CH4 data were used both for methane fluxes (FCH4; target variable) and tower-measured bio-meteorological variables (e.g., LE, GPP, TA; predictors)
  - Link to [FLUXNET.org variable descriptions](https://fluxnet.org/data/fluxnet-ch4-community-product/data-variables/)
      
      
**FLUXNET-CH4 Download Manifest**

```{r review-download-manifest, echo = F, message = F, warning = F}
knitr::kable(
  read_xlsx("tables/download-manifest.xlsx", skip = 4) %>% filter(SITE_ID != "AA-Flx") %>% head(10),
    type = "html")
```

**FLUXNET-CH4 Metadata**


```{r review-site-metadata, echo = F, message = F, warning = F}
knitr::kable(
  read_xlsx("tables/Table S1.xlsx") %>% select(1:16) %>% filter(!is.na(ID)) %>% head(10),
  type = "html")
```

      
**Gridded Data (Predictors)**

```{r review-gridded-data, echo = F, message = F, warning = F}
knitr::kable(
  read_xlsx("tables/Table S3.xlsx") %>% head(10),
    type = "html")
```

## 1. Forward feature selection (FFS) Setup

Read in training data from `data/final.csv` and a list of predictors from `data/predictors_metadata.csv`.

```{r read-ffs-data, message = F, warning = F}
training_data <- read_csv("data/final.csv")
predictor_metadata <- read_csv("data/predictors_metadata.csv")
feat_pairs <- read_csv("data/feat_pairs.csv")
```

Skim the training data:

```{r skim-training, echo = F, message = F, warning = F}
skim(training_data)
```

Select features and create indices:

```{r select-feature-names-indices}
feat <- predictor_metadata$Predictor
feat_l <- length(feat)
data_l <- length(training_data$Cluster)
```

Create pairwise feat combinations for FFS:

```{r create-feature-pairs}
feat_pairs_full <- combn(feat, 2, simplify = FALSE)
paste0("There are ", length(feat_pairs_full), " feature pairs")
```

Remove pairs of static predictors (unlikely to be informative):
**NOTE** this step is slow (~30 minutes). This chunk is currently skipped and the `feat_pairs` object is read in at `read-ffs-data` chunk.

```{r remove-static-pairs, eval = F}
static_predictors <- predictor_metadata %>% 
  filter(Content == "Spatial") %>% 
  dplyr::select(Predictor, Content)

feat_pairs_n <- length(feat_pairs_full)

feat_pairs_remove <- bind_cols(feat_pairs_full) %>% 
  gather(key = "pair", value = "Predictor") %>% 
  mutate(pair = str_remove(pair, "...")) %>% 
  left_join(static_predictors) %>% 
  filter(!is.na(Content)) %>% 
  group_by(pair) %>% 
  summarize(n_static = n()) %>% 
  filter(n_static == 2) %>% 
  dplyr::select(pair) %>% pull() %>% as.numeric()

feat_pairs <- feat_pairs_full[-feat_pairs_remove]

paste0("There are ", length(feat_pairs), " feature pairs after removing static pairs.")
```

Save `feat_pairs`:

```{r save-feat-pairs}
bind_cols(feat_pairs) %>% 
  gather(key = Pair, value = Predictor) %>% 
  mutate(Pair = str_remove(Pair,'...')) %>% 
  write_csv("data/feat_pairs.csv")
```

View `feat-pairs`:

```{r view-feat-pairs}
head(feat_pairs, 10)
```

## 2. FFS: First pair selection

Get training data fold number and fold names:

```{r get-training-folds}
set.seed(23)

# data inner folds 
folds <- training_data %>% 
  mutate(Cluster = as.factor(Cluster)) %>%
  dplyr::select(Cluster) %>%
  pull() %>%
  levels() %>%
  length()

fold_names <- training_data %>%
  group_by(Cluster) %>%
  summarize(Name = ID[1]) 
```

Setup ML folds:

```{r setup-ml-folds}
train_feat <- list()
train_label <- list()
validate_data <- list()

for (i in 1:folds) {
  train_label[[i]] <- training_data %>% 
    filter(!Cluster == i) %>% 
    dplyr::select(FCH4) %>% 
    pull()
  
  train_feat[[i]] <- training_data %>%
    filter(!Cluster == i) %>%
    dplyr::select(feat)
  
  validate_data[[i]] <- training_data %>%
    filter(Cluster == i) %>%
    dplyr::select(Cluster, FCH4, feat)
}

folds_index <- list() # need list within list (each inner list has all fold site except LOSO fold)

for (i in 1:folds) {
  x <- list()
  folds_index[[i]] <- x
}

for (i in 1:folds) {
  for (j in 1:folds) {
    folds_index[[i]][[j]] <- training_data %>% 
      filter(!Cluster == i) %>% 
      mutate(index = 1:n()) %>% 
      filter(!Cluster == j) %>% 
      dplyr::select(index) %>% 
      pull()
  }
  folds_index[[i]] <- folds_index[[i]][-i]
}
```

Are `folds_index`, `train_label`, `train_feat`, `validate_data` of the same length?

```{r fold-data-length-test}
length(folds_index) == length(train_label) & length(folds_index) == length(train_feat)  & length(folds_index) == length(validate_data)
```

Load FFS functions from source:

```{r ffs-functions}
source("code/fit_all_pairs.R")
source("code/fit_stepwise.R")
```


Identifying the first feature pair:

```{marginfigure}
**NOTE:** This step considers up to 33670 feature pairs which can take a long time without parallel processing. To speed up this step, you can use the `best_pair`, which we previously identified, to simply generate predictors and performance metrics for this best pair.
```

```{r identify-best-predictor-pair, warning = F}
set_index <- c(1:3)

# numCores <- detectCores()

best_pair <- c("TA", "canopyht")
best_pair <- list(best_pair)

rf_pred <- lapply(best_pair, fit_all_pairs)

for(i in 1){
  rf_pred[[i]] <- rf_pred[[i]] %>% 
    mutate(feat_pair = set_index[i])
}

for(i in 1){
  write_csv(rf_pred[[i]], 
            "output/ffs/1/rf_pred.csv")
}
```

Compute FFS First Pair metrics:

```{r compute-first-pair-metrics, echo = F}
rf_metrics <- list()

files <- list.files("output/ffs/1/", pattern = "rf_pred")
rf_pred <- lapply(paste0("output/ffs/1/", files), read_csv)

compute_metrics <- function(rf_pred) {
    rf_pred %>% 
    dplyr::select(FCH4, FCH4P) %>% 
    summarize(samples = n(),
              PMARE = 100/n() * sum(abs(FCH4 - FCH4P) / abs(FCH4)),
              R2 = cor(FCH4P, FCH4)^2,
              NSE = 1 - sum((FCH4 - FCH4P)^2) / sum((FCH4 - mean(FCH4))^2),
              MAE = sum(abs(FCH4 - FCH4P))/n(),
              nMAE = MAE/sd(FCH4),
              MeanO = mean(FCH4),
              MedO = median(FCH4),
              sdO = sd(FCH4),
              MeanP = mean(FCH4P),
              MedP = median(FCH4P),
              sdP = sd(FCH4P),
              nSD = sdP/sdO,
              Bias = mean(FCH4P - FCH4),
              cBias = abs(Bias)/sum(abs(Bias))*100,
              predictors = list(feat_pairs[[i]]) )
}

rf_metrics <- lapply(rf_pred, compute_metrics)

rf_metrics_all <- bind_rows(rf_metrics) %>% 
  arrange(MAE) %>% 
  rowwise() %>% 
  mutate(pred1 = predictors[1],
         pred2 = predictors[2]) %>% 
  dplyr::select(-predictors)

write_csv(rf_metrics_all, "output/ffs/1/rf_metrics_all.csv")
```

Look at metrics distribution (if many pairs have been considered):

```{r view-metrics}
rf_metrics_all %>% 
  ggplot(aes(R2)) +
  geom_histogram() + my_theme
ggsave("output/ffs/1/R2_distribution.png",
       width = 8, height = 15, units = c("cm"), dpi = 300) 

rf_metrics_all %>% 
  ggplot(aes(MAE)) +
  geom_histogram() + my_theme
ggsave("output/ffs/1/MAE_distribution.png",
       width = 8, height = 15, units = c("cm"), dpi = 300) 
```

Get the min MAE and max R2 (are they they from the same combination?):

```{r}
max(rf_metrics_all$R2)
min(rf_metrics_all$MAE)
rf_metrics_all
```

Yes both are for `canopyht` and `TA`.

## 2. Stepwise FFS (for first 13 steps, to avoid local minima)

```{r stepup-feat}
feat <- predictor_metadata$Predictor
feat_original <- feat
data_l <- length(training_data$Cluster)


feat_best <- c("TA", "canopyht")
feat_best_index <- c(which(feat == "TA"), 
                     which(feat == "canopyht"))

feat <- feat[- c(feat_best_index) ]
feat_l <- length(feat)
```

Setup ML folds:

```{r setup-ml-folds-2}
train_feat <- list()
train_label <- list()
validate_data <- list()

for (i in 1:folds) {
  train_label[[i]] <- training_data %>% filter(!Cluster == i) %>% dplyr::select(FCH4) %>% pull()
  train_feat[[i]] <- training_data %>% filter(!Cluster == i) %>% dplyr::select(all_of( feat_original) )
  validate_data[[i]] <- training_data %>% filter(Cluster == i) %>% dplyr::select(Cluster, FCH4, all_of(feat_original) )
}

length(train_label) & length(folds_index) == length(train_feat)  & length(folds_index) == length(validate_data)
```

Update compute metrics function (remove predictor list variable of length 2):

```{r revise-metrics-function}
compute_metrics <- function(rf_pred) {
    rf_pred %>% 
    dplyr::select(FCH4, FCH4P) %>% 
    summarize(samples = n(),
              PMARE = 100/n() * sum(abs(FCH4 - FCH4P) / abs(FCH4)),
              R2 = cor(FCH4P, FCH4)^2,
              NSE = 1 - sum((FCH4 - FCH4P)^2) / sum((FCH4 - mean(FCH4))^2),
              MAE = sum(abs(FCH4 - FCH4P))/n(),
              nMAE = MAE/sd(FCH4),
              MeanO = mean(FCH4),
              MedO = median(FCH4),
              sdO = sd(FCH4),
              MeanP = mean(FCH4P),
              MedP = median(FCH4P),
              sdP = sd(FCH4P),
              nSD = sdP/sdO,
              Bias = mean(FCH4P - FCH4),
              cBias = abs(Bias)/sum(abs(Bias))*100) 
}
```

Train multiple RFs (with CV) for FFS to select the next 10 best predictors:

```{r select-next-10-best-predictors, warning = F}
feat_initial <- 2
feat_best_row <- list()
rf_metrics_all <- list()

for(k in 2:10){
  
# create index for a list of features
feat_l <- length(feat)
set_index <- c(1:feat_l)
feat_list <- as.list(feat)

# numCores <- detectCores()

# call fit a stepwise function to train RFs using one additional predictor
rf_pred <- lapply(feat_list, fit_stepwise)

for(l in 1:feat_l){
  rf_pred[[l]] <- rf_pred[[l]] %>% 
    mutate(feat_single = feat[l])
}

for(l in 1:feat_l){
  write_csv(rf_pred[[l]], paste0("output/ffs/",k,"/rf_pred_", k, "thstep_", set_index[l], "_", feat[l],  ".csv"))
}

# call compute_metrics function
rf_metrics <- lapply(rf_pred, compute_metrics)

# bind rows and append feature column, then arrange by MAE
rf_metrics_all[[k]] <- bind_rows(rf_metrics) %>% 
  cbind(feat) %>% 
  arrange(MAE) 

# save the row of the best performing new predictor
feat_best_row[[k]] <- rf_metrics_all[[k]] %>% 
    filter(MAE == min(MAE))
  
# get the specific predictor name
feat_best_add <- feat_best_row[[k]] %>% 
    dplyr::select(feat) %>% 
    pull() %>% as.character()
  
# add to initial best_feat
feat_best <- c(feat_best, feat_best_add)
  
# add one to feat_initial size
feat_initial <- feat_initial + 1
  
# remove feat_best from feat
feat_best_add_index <- which(feat == feat_best_add)
feat <- feat[- feat_best_add_index ]
  
print(paste('added', feat_best_add))
}
```

Save all output from stepwise FFS:

```{r save-output}
feat_best_row_all <- bind_rows(feat_best_row)

for(i in 2:length(rf_metrics_all)) {
  rf_metrics_all[[i]] <- rf_metrics_all[[i]] %>% 
    mutate(iteration = i)
}
rf_metrics_all <- bind_rows(rf_metrics_all)
  
write_csv(feat_best %>% as_tibble(), "output/ffs/stepwise/feat_best.csv")

write_csv(feat_best_row_all, "output/ffs/stepwise/feat_best_row_all.csv")

write_csv(rf_metrics_all, "output/ffs/stepwise/rf_metrics_all.csv")

```

Reload initial pair:

```{r reload-initial-pair}
feat_best_initial <- read.csv(paste(loc, "ffs/first-pair/rf-metrics/rf.metrics.all.csv", sep = "")) %>% 
  mutate(feat = paste(pred1, pred2, sep = ", ")) %>% 
  dplyr::select(-pred1, -pred2)
feat_best_row_all <- read.csv(paste(loc,  "ffs/stepwise/feat_best_row_all.csv", sep = ""))

feat_best_initial <- feat_best_initial %>% 
  filter(MAE == min(MAE)) 

feat_best_row_final <- feat_best_initial %>% 
  bind_rows(feat_best_row_all) %>% 
  mutate(predictors = 1:n()+1)

write.csv(feat_best_row_final, 
          paste(loc, "ffs/stepwise/feat_best_row_final.csv", sep = ""),
          row.names = F)
```

Output plots for evolution of predictors:

```{r pred-evolution-plots}
feat_best <- feat_best_row_final %>% dplyr::select(feat) %>% pull()

feat_best_row_final %>% 
  ggplot(aes(predictors, R2)) +
  geom_point() +
  geom_line() +
  scale_x_continuous(breaks = c(2:12), labels = feat_best) +
  my_theme +
  theme(axis.text.x = element_text(angle = -45, hjust = 0))
ggsave(paste(loc, "ffs/stepwise/R2_evolve.png", sep = ""),
       width = 15, height = 12, units = c("cm"), dpi = 300)

feat_best_row_final %>% 
  ggplot(aes(predictors, MAE)) +
  geom_point() +
  geom_line() +
  scale_x_continuous(breaks = c(2:12), labels = feat_best) +
  my_theme +
  theme(axis.text.x = element_text(angle = -45, hjust = 0))
ggsave(paste(loc, "ffs/stepwise/MAE_evolve.png", sep = ""),
       width = 15, height = 12, units = c("cm"), dpi = 300)

```

Reload initial pair:

```{r reload-initial-pair}
feat_best_initial <- read_csv("output/rf_metrics_all.csv") %>% 
  mutate(feat = paste(pred1, pred2, sep = ", ")) %>% 
  dplyr::select(-pred1, -pred2)
feat_best_row_all <- read_csv("output/ffs/stepwise/feat_best_row_all.csv")

feat_best_initial <- feat_best_initial %>% 
  filter(MAE == min(MAE)) 

feat_best_row_final <- feat_best_initial %>% 
  bind_rows(feat_best_row_all) %>% 
  mutate(predictors = 1:n()+1)

write_csv(feat_best_row_final, 
          "output/ffs/stepwise/feat_best_row_final.csv")
```

Output plots for evolution of predictors:

```{r plot-ffs-evolution}
feat_best <- feat_best_row_final %>% dplyr::select(feat) %>% pull()

feat_best_row_final %>% 
  ggplot(aes(predictors, R2)) +
  geom_point() +
  geom_line() +
  scale_x_continuous(breaks = c(1:10), labels = feat_best) +
  my_theme +
  theme(axis.text.x = element_text(angle = -45, hjust = 0))
ggsave("output/ffs/stepwise/R2_evolve.png",
       width = 15, height = 12, units = c("cm"), dpi = 300)

feat_best_row_final %>% 
  ggplot(aes(predictors, MAE)) +
  geom_point() +
  geom_line() +
  scale_x_continuous(breaks = c(1:10), labels = feat_best) +
  my_theme +
  theme(axis.text.x = element_text(angle = -45, hjust = 0))
ggsave("output/ffs/stepwise/MAE_evolve.png",
       width = 15, height = 12, units = c("cm"), dpi = 300)

```

## 3. Cross Validation (Train, Predict)

Read in training data:

```{r read-training-data}
data <- read.csv("data/final.csv")
```

Read in feat list from FFS results:

```{r read-ffs-feat}
feat <- read_csv("output/ffs/stepwise/feat_best_row_final.csv") %>%
  dplyr::select(feat) %>% pull() %>% as.character()
feat <- c("TA", "canopyht", feat[2:length(feat)])
feat <- feat[1:6] # select best
feat_l <- length(feat)
```

Finalize label and feat data:

```{r final-train-test-data}
data_l <- length(data$Cluster)

folds <- data %>% dplyr::select(Cluster) %>% max()
fold_names <- data %>% group_by(Cluster) %>% summarize(Name = ID[1]) 

# set up folds
train_feat <- list()
train_label <- list()
test_data <- list()

for (i in 1:folds) {
  train_label[[i]] <- data %>% filter(!Cluster == i) %>% dplyr::select(FCH4) %>% pull()
  train_feat[[i]] <- data %>% filter(!Cluster == i) %>% dplyr::select(all_of(feat))
  test_data[[i]] <- data %>% filter(Cluster == i) %>% dplyr::select(Cluster, FCH4, all_of(feat))
}

folds_index <- list() # need list within list (each inner list has all fold site except LOSO fold)
for (i in 1:folds) {
  x <- list()
  folds_index[[i]] <- x
}

for (i in 1:folds) {
  for (j in 1:folds) {
    folds_index[[i]][[j]] <- data %>% 
      filter(!Cluster == i) %>% 
      mutate(index = 1:n()) %>% 
      filter(!Cluster == j) %>% 
      dplyr::select(index) %>% 
      pull()
  }
  folds_index[[i]] <- folds_index[[i]][-i]
}
```

Train RF:

```{r train-rf-final, warning = F}
tgrid <- list()
myControl <- list()

## Create tune-grid
tgrid <- expand.grid(
  mtry = c(2, 4, 6),
  splitrule = "variance", 
  min.node.size = c(5, 50, 100)
)

rf_model <- list()
for (i in 1:folds) {
  
  ## Create trainControl object
  myControl <- trainControl(
    method = "cv",
    allowParallel = TRUE,
    verboseIter = TRUE, 
    returnData = FALSE,
    index = folds_index[[i]]
  )
  
  ## train rf on folds
  rf_model[[i]] <- train(
    x = train_feat[[i]], 
    y = train_label[[i]],
    num.trees = 100, # start at 10xfeat, drop to 100
    method = 'ranger',
    trControl = myControl,
    tuneGrid = tgrid,
    importance = 'permutation',
    metric = "MAE"
  )
  print(i)
}

# save loocv model ensemble
saveRDS(rf_model, "output/ensembles/cv/best-feat.rds") # local dir.
```

Look at r2 and MAE for all models:

```{r get-best-model-metrics}
mean_MAE <- c()
mean_r2 <- c()
tune_r2 <- list()
tune_MAE <- list()
tune_r2se <- list()
tune_MAEse <- list()
for (i in 1:length(rf_model)){
  mean_MAE[i] <- sqrt(rf_model[[i]]$finalModel$prediction.error) # final model, out of bag metrics
  mean_r2[i] <- rf_model[[i]]$finalModel$r.squared
  tune_r2[[i]] <- rf_model[[i]]$results[,c(5)] # inner-fold cross validation metrics
  tune_MAE[[i]] <- rf_model[[i]]$results[,c(4)]
  tune_r2se[[i]] <- rf_model[[i]]$results[,c(6)]
  tune_MAEse[[i]] <- rf_model[[i]]$results[,c(4)]
  
}
mean(mean_MAE); mean(mean_r2) # final model for the fold, out of bag metrics


tune_r2s <- cbind(rf_model[[1]]$results[,c(1,3)],bind_cols(tune_r2)) %>%  
  gather(key = "fold", value = "R2", 3:22)
tune_MAEs <- cbind(rf_model[[1]]$results[,c(1,3)],bind_cols(tune_MAE)) %>% 
  gather(key = "fold", value = "MAE", 3:22)

mean(tune_MAEs$MAE); mean(tune_r2s$R2)  # inner MAE and R2

metrics <- c("final_fold_oob_MAE", "final_fold_oob_R2", "inner_cv_MAE", "inner_cv_R2")
values <- c(mean(mean_MAE), mean(mean_r2), mean(tune_MAEs$MAE), mean(tune_r2s$R2) )

as_tibble(cbind(metrics, values)) %>% 
  write_csv("output/ensembles/cv/best_feat_cv_metrics.csv")
```

Get all hold out predictions:

```{r get-hold-out-pred}
rf_pred <- list()
for (i in 1:folds) {
  rf_pred[[i]] <- data %>% 
    filter(Cluster== i) %>%   
    mutate(FCH4P = predict(rf_model[[i]], .),
           index = 1:n())
}
rf_pred_all <- bind_rows(rf.pred)

write_csv(rf_pred_all,"output/predictions/cv/best_feat_pred.csv")
```

Quick look at pred vs obs:

```{r pred-vs-obs}
class_col_vector <- rep(c("#E78AC3","#F1E2CC","#33A02C","#377EB8","#E41A1C","#999999"),10)

rf_pred_all %>% 
  ggplot(aes(FCH4, FCH4P)) +
  geom_abline(slope = 1) +
  geom_point(alpha = 0.2) +
  xlab(label = expression("FCH4 (nmol m"^{-2}*" s"^{-1}*")")) +
  ylab(label = expression("FCH4P (nmol m"^{-2}*" s"^{-1}*")")) +
  my_theme
ggsave("output/predictions/cv/best_feat_pvo.png",
       width = 15, height = 8, units = c("cm"), dpi = 300)
```

## 3. Cross Validation (Validate)

Read csv:

```{r read}
rf_pred_all <- read_csv("output/predictions/cv/best_feat_pred.csv")
```

Get nice plot colors:

```{r plot-colors}
qual_col_pals = brewer.pal.info[brewer.pal.info$category == 'qual',]
col_vector = unlist(mapply(brewer.pal, qual_col_pals$maxcolors, rownames(qual_col_pals)))
col_vector_values = sample(col_vector, length(levels(factor(rf.pred.all$Cluster))), replace=FALSE)
col_vector_values[1:6]

class_col_vector <- c("#E78AC3","orange","#33A02C","#377EB8","#E41A1C","#999999")
```

Create a Climate-by-latitude class:

```{r create-climate-class}
rf_pred_all <- rf_pred_all %>% 
  mutate(Climate = ifelse(Latitude > 70 | Latitude < -70, "1", NA),
         Climate = ifelse(Latitude < 70 & Latitude > 50 | Latitude > -70 & Latitude < -50, "2", Climate),
         Climate = ifelse(Latitude < 50 & Latitude > 23 | Latitude > -50 & Latitude < -23, "3", Climate),
         Climate = ifelse(Latitude < 23 & Latitude > 0 | Latitude > -23 & Latitude < 0, "4", Climate)) %>% 
  rename(Class = Site.Classification)
```

Look at FCH4 predictions histograms:

```{r pred-histograms}
rf_pred_all %>% 
  dplyr::select(FCH4,FCH4P) %>% 
  gather(key = "Flux", value = "Value", 1:2) %>% 
  ggplot(aes(Value, fill = Flux)) +
  geom_histogram(aes(Value), fill = 'black') +
  geom_histogram(alpha = 0.3) +
  scale_color_manual(values = class_col_vector) +
  facet_wrap(~Flux) +
  my_theme
ggsave("output/predictions/cv/simple_histograms.png",
       width = 20, height = 10, units = c("cm"), dpi = 300)
```

Test using bias correction (notice histograms show a loss of very high and very low fluxes)

```{r test-bias-cor}
splinemod <- smooth.spline(y=rf_pred_all$FCH4, x=rf_pred_all$FCH4P, spar = 2)
plot(rf_pred_all$FCH4P,rf_pred_all$FCH4, xlim = c(0,1000), ylim = c(0,1000))
abline(0,1,col = 'blue')
lines(splinemod, col="white", lwd=5)

```

There is no visible effect. 

Visualize bias (in residuals):

```{r visualize-bias}
ungroup(rf_pred_all) %>% 
  mutate(index = 1:n()) %>% 
  ggplot(aes(x = NULL, y = FCH4P - FCH4, fill = Class)) +
  geom_abline(intercept = 0) +
  geom_boxplot(width = 2, alpha = 0.8) + my_theme + 
  theme(axis.line.x = element_blank(), axis.title.x = element_blank(), 
        axis.text.x = element_blank(), axis.ticks.x = element_blank()) +
  ylab(label = expression("Error (nmol m"^{-2}*" s"^{-1}*")")) +
  scale_fill_manual(values = class_col_vector) 
ggsave("output/predictions/cv/residuals_error.png",
       width = 13, height = 15, units = c("cm"), dpi = 300)
```

Global Metrics:

```{r global-metrics}
global <- ungroup(rf_pred_all) %>% 
  # filter(!ID == "USOWC") %>%
  summarize(samples = n(),
            R2 = cor(FCH4P, FCH4)^2,
            NSE = 1 - sum((FCH4 - FCH4P)^2) / sum((FCH4 - mean(FCH4))^2),
            MAE = sum(abs(FCH4 - FCH4P))/n(),
            nMAE = MAE/sd(FCH4),
            MeanO = mean(FCH4),
            MedO = median(FCH4),
            sdO = sd(FCH4),
            MeanP = mean(FCH4P),
            MedP = median(FCH4P),
            sdP = sd(FCH4P),
            nSD = sdP/sdO,
            Bias = mean(FCH4P - FCH4),
            cBias = abs(Bias)/sum(abs(Bias))*100) 

global_ID <- ungroup(rf_pred_all) %>% 
    # filter(!ID == "USOWC") %>%
  group_by(ID) %>% 
  summarize(samples = n(),
            R2 = cor(FCH4P, FCH4)^2,
            NSE = 1 - sum((FCH4 - FCH4P)^2) / sum((FCH4 - mean(FCH4))^2),
            MAE = sum(abs(FCH4 - FCH4P))/n(),
            nMAE = MAE/sd(FCH4),
            MeanO = mean(FCH4),
            MedO = median(FCH4),
            sdO = sd(FCH4),
            MeanP = mean(FCH4P),
            MedP = median(FCH4P),
            sdP = sd(FCH4P),
            nSD = sdP/sdO,
            Bias = mean(FCH4P - FCH4),
            cBias = abs(Bias)/sum(abs(Bias))*100) 

global_ID_monthly <- ungroup(rf_pred_all) %>% 
      # filter(!ID == "USOWC") %>%
  group_by(ID, Month) %>% 
  summarize(samples = n(),
            R2 = cor(FCH4P, FCH4)^2,
            NSE = 1 - sum((FCH4 - FCH4P)^2) / sum((FCH4 - mean(FCH4))^2),
            MAE = sum(abs(FCH4 - FCH4P))/n(),
            nMAE = MAE/sd(FCH4),
            MeanO = mean(FCH4),
            MedO = median(FCH4),
            sdO = sd(FCH4),
            MeanP = mean(FCH4P),
            MedP = median(FCH4P),
            sdP = sd(FCH4P),
            nSD = sdP/sdO,
            Bias = mean(FCH4P - FCH4),
            cBias = abs(Bias)/sum(abs(Bias))*100) 

global <- bind_rows(global, global_ID, global_ID_monthly)

write_csv(global, "output/predictions/cv/global.csv")


global <- ungroup(rf_pred_all) %>% 
  filter(!ID == "USOWC") %>%
  summarize(samples = n(),
            R2 = cor(FCH4P, FCH4)^2,
            NSE = 1 - sum((FCH4 - FCH4P)^2) / sum((FCH4 - mean(FCH4))^2),
            MAE = sum(abs(FCH4 - FCH4P))/n(),
            nMAE = MAE/sd(FCH4),
            MeanO = mean(FCH4),
            MedO = median(FCH4),
            sdO = sd(FCH4),
            MeanP = mean(FCH4P),
            MedP = median(FCH4P),
            sdP = sd(FCH4P),
            nSD = sdP/sdO,
            Bias = mean(FCH4P - FCH4),
            cBias = abs(Bias)/sum(abs(Bias))*100) 

global_ID <- ungroup(rf_pred_all) %>% 
    filter(!ID == "USOWC") %>%
  group_by(ID) %>% 
  summarize(samples = n(),
            R2 = cor(FCH4P, FCH4)^2,
            NSE = 1 - sum((FCH4 - FCH4P)^2) / sum((FCH4 - mean(FCH4))^2),
            MAE = sum(abs(FCH4 - FCH4P))/n(),
            nMAE = MAE/sd(FCH4),
            MeanO = mean(FCH4),
            MedO = median(FCH4),
            sdO = sd(FCH4),
            MeanP = mean(FCH4P),
            MedP = median(FCH4P),
            sdP = sd(FCH4P),
            nSD = sdP/sdO,
            Bias = mean(FCH4P - FCH4),
            cBias = abs(Bias)/sum(abs(Bias))*100) 

global_ID_monthly <- ungroup(rf_pred_all) %>% 
      filter(!ID == "USOWC") %>%
  group_by(ID, Month) %>% 
  summarize(samples = n(),
            R2 = cor(FCH4P, FCH4)^2,
            NSE = 1 - sum((FCH4 - FCH4P)^2) / sum((FCH4 - mean(FCH4))^2),
            MAE = sum(abs(FCH4 - FCH4P))/n(),
            nMAE = MAE/sd(FCH4),
            MeanO = mean(FCH4),
            MedO = median(FCH4),
            sdO = sd(FCH4),
            MeanP = mean(FCH4P),
            MedP = median(FCH4P),
            sdP = sd(FCH4P),
            nSD = sdP/sdO,
            Bias = mean(FCH4P - FCH4),
            cBias = abs(Bias)/sum(abs(Bias))*100) 

global <- bind_rows(global, global_ID, global_ID_monthly)

write_csv(global, "output/predictions/cv/global_wo_usowc.csv")
```

Northern latitude metrics for comparison to Peltola et al. (2019):


```{r northern-lat-metrics}
# for monthly global comparisons
ungroup(rf_pred_all) %>% 
  filter(!ID == "USOWC") %>%
  group_by(ID, Year, Month) %>% 
  summarize(FCH4 = mean(FCH4, na.rm = T),
         FCH4P = mean(FCH4P, na.rm = T)) %>% 
  ungroup() %>% 
  summarize(samples = n(),
            R2 = cor(FCH4P, FCH4)^2,
            NSE = 1 - sum((FCH4 - FCH4P)^2) / sum((FCH4 - mean(FCH4))^2),
            MAE = sum(abs(FCH4 - FCH4P))/n(),
            nMAE = MAE/sd(FCH4),
            MeanO = mean(FCH4),
            MedO = median(FCH4),
            sdO = sd(FCH4),
            MeanP = mean(FCH4P),
            MedP = median(FCH4P),
            sdP = sd(FCH4P),
            nSD = sdP/sdO,
            Bias = mean(FCH4P - FCH4),
            cBias = abs(Bias)/sum(abs(Bias))*100) 

# for monthly northern comparisons
ungroup(rf_pred_all) %>% 
  filter(!ID == "USOWC" & Latitude >= 45) %>%
  group_by(ID, Year, Month) %>% 
  summarize(FCH4 = mean(FCH4, na.rm = T),
         FCH4P = mean(FCH4P, na.rm = T)) %>% 
  ungroup() %>% 
  summarize(samples = n(),
            R2 = cor(FCH4P, FCH4)^2,
            NSE = 1 - sum((FCH4 - FCH4P)^2) / sum((FCH4 - mean(FCH4))^2),
            MAE = sum(abs(FCH4 - FCH4P))/n(),
            nMAE = MAE/sd(FCH4),
            MeanO = mean(FCH4),
            MedO = median(FCH4),
            sdO = sd(FCH4),
            MeanP = mean(FCH4P),
            MedP = median(FCH4P),
            sdP = sd(FCH4P),
            nSD = sdP/sdO,
            Bias = mean(FCH4P - FCH4),
            cBias = abs(Bias)/sum(abs(Bias))*100) 
```


Site-mean metrics:

```{r site-mean-metrics}
## performance metrics broken down by site-means, seasonal cycle and weekly/daily anomalies
# site-means
sitemean <- ungroup(rf_pred_all) %>% 
  group_by(ID) %>%
  # filter(!ID == "USOWC") %>%
  summarize(MeanO = mean(FCH4, na.rm=TRUE),
            MeanP = mean(FCH4P, na.rm=TRUE),
            MedO = median(FCH4, na.rm=TRUE),
            MedP = median(FCH4P, na.rm=TRUE),
            IGBP = IGBP[1],
            Class = NA) %>% 
  ungroup() %>% 
  summarize(Name = "Site means",
            Samples = n(),
            R2 = cor(MeanP, MeanO)^2,
            NSE = 1 - sum((MeanO - MeanP)^2) / sum((MeanO - mean(MeanO))^2),
            MAE = sum(abs(MeanO - MeanP))/n(),
            nMAE = MAE/sd(MeanO),
            MeanFCH4 = mean(MeanO),
            MedFCH4 = median(MeanO),
            sdFCH4 = sd(MeanO),
            MeanFCH4P = mean(MeanP),
            MedFCH4P = median(MeanP),
            sdFCH4P = sd(MeanP),
            nSD = sdFCH4P/sdFCH4,
            Bias = mean(MeanP - MeanO),
            Class = NA) %>% 
  ungroup() %>% 
  mutate(cBias = abs(Bias)/sum(abs(Bias))*100)

# by-ID, grouped by Class 
sitemean_class <- ungroup(rf_pred_all) %>% 
    # filter(!ID == "USOWC") %>%
  group_by(ID) %>%
  summarize(MeanO = mean(FCH4, na.rm=TRUE),
            MeanP = mean(FCH4P, na.rm=TRUE),
            MedO = median(FCH4, na.rm=TRUE),
            MedP = median(FCH4P, na.rm=TRUE),
            Class = Class[1]) %>%  
  ungroup() %>% 
  group_by(Class) %>% 
  summarize(Name = "Site means Class",
            Samples = n(),
            R2 = cor(MeanP, MeanO)^2,
            NSE = 1 - sum((MeanO - MeanP)^2) / sum((MeanO - mean(MeanO))^2),
            MAE = sum(abs(MeanO - MeanP))/n(),
            nMAE = MAE/sd(MeanO),
            MeanFCH4 = mean(MeanO),
            MedFCH4 = median(MeanO),
            sdFCH4 = sd(MeanO),
            MeanFCH4P = mean(MeanP),
            MedFCH4P = median(MeanP),
            sdFCH4P = sd(MeanP),
            nSD = sdFCH4P/sdFCH4,
            Bias = mean(MeanP - MeanO)) %>% 
  ungroup() %>% 
  mutate(cBias = abs(Bias)/sum(abs(Bias))*100)

# by-ID, grouped by Climate 
sitemean_climate <- ungroup(rf_pred_all) %>% 
    # filter(!ID == "USOWC") %>%
  group_by(ID) %>%
  summarize(MeanO = mean(FCH4, na.rm=TRUE),
            MeanP = mean(FCH4P, na.rm=TRUE),
            MedO = median(FCH4, na.rm=TRUE),
            MedP = median(FCH4P, na.rm=TRUE),
            Climate = Climate[1],
            Class = NA) %>%  
  ungroup() %>% 
  group_by(Climate) %>% 
  summarize(Name = "Site means Climate",
            Samples = n(),
            R2 = cor(MeanP, MeanO)^2,
            NSE = 1 - sum((MeanO - MeanP)^2) / sum((MeanO - mean(MeanO))^2),
            MAE = sum(abs(MeanO - MeanP))/n(),
            nMAE = MAE/sd(MeanO),
            MeanFCH4 = mean(MeanO),
            MedFCH4 = median(MeanO),
            sdFCH4 = sd(MeanO),
            MeanFCH4P = mean(MeanP),
            MedFCH4P = median(MeanP),
            sdFCH4P = sd(MeanP),
            nSD = sdFCH4P/sdFCH4,
            Bias = mean(MeanP - MeanO), 
            Class = NA) %>% 
  ungroup() %>% 
  mutate(cBias = abs(Bias)/sum(abs(Bias))*100)

# metrics (by-site for component)
sitemean_id <- ungroup(rf_pred_all) %>% 
    # filter(!ID == "USOWC") %>%
  group_by(ID) %>%
  summarize(MeanO = mean(FCH4, na.rm=TRUE),
            MeanP = mean(FCH4P, na.rm=TRUE),
            MedO = median(FCH4, na.rm=TRUE),
            MedP = median(FCH4P, na.rm=TRUE),
            Class = Class[1]) %>%  
  ungroup() %>% 
  group_by(ID) %>% 
  summarize(Name = "Site means ID",
            Samples = n(),
            R2 = cor(MeanP, MeanO)^2,
            NSE = 1 - sum((MeanO - MeanP)^2) / sum((MeanO - mean(MeanO))^2),
            MAE = sum(abs(MeanO - MeanP))/n(),
            nMAE = MAE/sd(MeanO),
            MeanFCH4 = mean(MeanO),
            MedFCH4 = median(MeanO),
            sdFCH4 = sd(MeanO),
            MeanFCH4P = mean(MeanP),
            MedFCH4P = median(MeanP),
            sdFCH4P = sd(MeanP),
            nSD = sdFCH4P/sdFCH4,
            Bias = mean(MeanP - MeanO),
            Class = Class[1]) %>% 
  ungroup() %>% 
  mutate(cBias = abs(Bias)/sum(abs(Bias))*100)

# join sitemean
sitemean_data <- bind_rows(sitemean, sitemean_class, sitemean_climate, sitemean_id)

write_csv(sitemean_data, "output/predictions/cv/sitemean.csv")

## METRICS WITHOUT USOWC
# site-means
sitemean <- ungroup(rf_pred_all) %>% 
  group_by(ID) %>%
  filter(!ID == "USOWC") %>%
  summarize(MeanO = mean(FCH4, na.rm=TRUE),
            MeanP = mean(FCH4P, na.rm=TRUE),
            MedO = median(FCH4, na.rm=TRUE),
            MedP = median(FCH4P, na.rm=TRUE),
            IGBP = IGBP[1],
            Class = NA) %>% 
  ungroup() %>% 
  summarize(Name = "Site means",
            Samples = n(),
            R2 = cor(MeanP, MeanO)^2,
            NSE = 1 - sum((MeanO - MeanP)^2) / sum((MeanO - mean(MeanO))^2),
            MAE = sum(abs(MeanO - MeanP))/n(),
            nMAE = MAE/sd(MeanO),
            MeanFCH4 = mean(MeanO),
            MedFCH4 = median(MeanO),
            sdFCH4 = sd(MeanO),
            MeanFCH4P = mean(MeanP),
            MedFCH4P = median(MeanP),
            sdFCH4P = sd(MeanP),
            nSD = sdFCH4P/sdFCH4,
            Bias = mean(MeanP - MeanO),
            Class = NA) %>% 
  ungroup() %>% 
  mutate(cBias = abs(Bias)/sum(abs(Bias))*100)

# by-ID, grouped by Class 
sitemean_class <- ungroup(rf_pred_all) %>% 
    filter(!ID == "USOWC") %>%
  group_by(ID) %>%
  summarize(MeanO = mean(FCH4, na.rm=TRUE),
            MeanP = mean(FCH4P, na.rm=TRUE),
            MedO = median(FCH4, na.rm=TRUE),
            MedP = median(FCH4P, na.rm=TRUE),
            Class = Class[1]) %>%  
  ungroup() %>% 
  group_by(Class) %>% 
  summarize(Name = "Site means Class",
            Samples = n(),
            R2 = cor(MeanP, MeanO)^2,
            NSE = 1 - sum((MeanO - MeanP)^2) / sum((MeanO - mean(MeanO))^2),
            MAE = sum(abs(MeanO - MeanP))/n(),
            nMAE = MAE/sd(MeanO),
            MeanFCH4 = mean(MeanO),
            MedFCH4 = median(MeanO),
            sdFCH4 = sd(MeanO),
            MeanFCH4P = mean(MeanP),
            MedFCH4P = median(MeanP),
            sdFCH4P = sd(MeanP),
            nSD = sdFCH4P/sdFCH4,
            Bias = mean(MeanP - MeanO)) %>% 
  ungroup() %>% 
  mutate(cBias = abs(Bias)/sum(abs(Bias))*100)

# by-ID, grouped by Climate 
sitemean_climate <- ungroup(rf_pred_all) %>% 
    filter(!ID == "USOWC") %>%
  group_by(ID) %>%
  summarize(MeanO = mean(FCH4, na.rm=TRUE),
            MeanP = mean(FCH4P, na.rm=TRUE),
            MedO = median(FCH4, na.rm=TRUE),
            MedP = median(FCH4P, na.rm=TRUE),
            Climate = Climate[1],
            Class = NA) %>%  
  ungroup() %>% 
  group_by(Climate) %>% 
  summarize(Name = "Site means Climate",
            Samples = n(),
            R2 = cor(MeanP, MeanO)^2,
            NSE = 1 - sum((MeanO - MeanP)^2) / sum((MeanO - mean(MeanO))^2),
            MAE = sum(abs(MeanO - MeanP))/n(),
            nMAE = MAE/sd(MeanO),
            MeanFCH4 = mean(MeanO),
            MedFCH4 = median(MeanO),
            sdFCH4 = sd(MeanO),
            MeanFCH4P = mean(MeanP),
            MedFCH4P = median(MeanP),
            sdFCH4P = sd(MeanP),
            nSD = sdFCH4P/sdFCH4,
            Bias = mean(MeanP - MeanO), 
            Class = NA) %>% 
  ungroup() %>% 
  mutate(cBias = abs(Bias)/sum(abs(Bias))*100)

# metrics (by-site for component)
sitemean_id <- ungroup(rf_pred_all) %>% 
    filter(!ID == "USOWC") %>%
  group_by(ID) %>%
  summarize(MeanO = mean(FCH4, na.rm=TRUE),
            MeanP = mean(FCH4P, na.rm=TRUE),
            MedO = median(FCH4, na.rm=TRUE),
            MedP = median(FCH4P, na.rm=TRUE),
            Class = Class[1]) %>%  
  ungroup() %>% 
  group_by(ID) %>% 
  summarize(Name = "Site means ID",
            Samples = n(),
            R2 = cor(MeanP, MeanO)^2,
            NSE = 1 - sum((MeanO - MeanP)^2) / sum((MeanO - mean(MeanO))^2),
            MAE = sum(abs(MeanO - MeanP))/n(),
            nMAE = MAE/sd(MeanO),
            MeanFCH4 = mean(MeanO),
            MedFCH4 = median(MeanO),
            sdFCH4 = sd(MeanO),
            MeanFCH4P = mean(MeanP),
            MedFCH4P = median(MeanP),
            sdFCH4P = sd(MeanP),
            nSD = sdFCH4P/sdFCH4,
            Bias = mean(MeanP - MeanO),
            Class = Class[1]) %>% 
  ungroup() %>% 
  mutate(cBias = abs(Bias)/sum(abs(Bias))*100)

# join sitemean
sitemean_data <- bind_rows(sitemean, sitemean_class, sitemean_climate, sitemean_id)
write_csv(sitemean_data, "output/predictions/cv/sitemean_wo_usowc.csv")
```

Other sitemean plots:

```{r other-site-mean-plots}

sitemean_data <- read_csv("output/predictions/cv/sitemean_wo_usowc.csv")

# plot histogram of site year performance: BIAS
sitemean_data %>% 
  filter(Name == "Site means ID") %>% 
  dplyr::select(ID, Class, MAE, nMAE, Bias, cBias) %>% 
  gather(key = "Metric", value = "Score", 3:6) %>% 
  filter(Metric %in% c("Bias", "cBias")) %>% 
  ggplot(aes(Score, fill = Class)) +
  geom_histogram() +
  facet_wrap(~Metric, scales = 'free', ncol = 1) +
  scale_fill_manual(values = rep(class_col_vector,8)) +
  my_theme
ggsave("output/predictions/cv/sitemean_histogram_bias.png",
       width = 13, height = 24, units = c("cm"), dpi = 300)

# plot histogram of site year performance: MAE
sitemean_data %>% 
  filter(Name == "Site means ID") %>% 
  dplyr::select(ID, Class, MAE, nMAE, Bias, cBias) %>% 
  gather(key = "Metric", value = "Score", 3:6) %>% 
  filter(Metric %in% c("MAE", "nMAE")) %>% 
  ggplot(aes(Score, fill = Class)) +
  geom_histogram() +
  facet_wrap(~Metric, scales = 'free', ncol = 1) +
  scale_fill_manual(values = rep(class_col_vector,8)) +
  my_theme
ggsave("output/predictions/cv/sitemean_histogram_mae.png",
       width = 13, height = 24, units = c("cm"), dpi = 300)

# global site-mean comparison
ungroup(rf_pred_all) %>% 
  # group_by(ID, Year) %>% 
  group_by(ID) %>% 
  summarize(MeanO = mean(FCH4, na.rm=TRUE),
            MeanP = mean(FCH4P, na.rm=TRUE),
            MedO = median(FCH4, na.rm=TRUE),
            MedP = median(FCH4P, na.rm=TRUE),
            Class = Class[1]) %>% 
  ggplot(aes(MeanO, MeanP, col = Class)) +
  # scale_x_log10(limits = c(6,700)) +
  # scale_y_log10(limits = c(6,700)) +
  geom_point(size = 4, alpha = 0.85) +
  geom_abline(slope = 1, intercept = 0, colour = 'black', linetype = 2) +
  scale_color_manual(values = class_col_vector) +
  my_theme +
  labs(x= expression('Observed '*CH[4]*' Flux (nmol m'^{-2}*' s'^{-1}*')'), y = expression('Predicted '*CH[4]*' Flux (nmol m'^{-2}*' s'^{-1}*')'))
ggsave("output/predictions/cv/sitemean_pvo.png",
       width = 13, height = 24, units = c("cm"), dpi = 300)

# global site-mean comparison log10
ungroup(rf_pred_all) %>% 
  # group_by(ID, Year) %>% 
  group_by(ID) %>% 
  summarize(MeanO = mean(FCH4, na.rm=TRUE),
            MeanP = mean(FCH4P, na.rm=TRUE),
            MedO = median(FCH4, na.rm=TRUE),
            MedP = median(FCH4P, na.rm=TRUE),
            Class = Class[1]) %>% 
  ggplot(aes(MeanO, MeanP, col = Class)) +
  scale_x_log10(limits = c(6,700)) +
  scale_y_log10(limits = c(6,700)) +
  geom_point(size = 4, alpha = 0.85) +
  geom_abline(slope = 1, intercept = 0, colour = 'grey') +
  scale_color_manual(values = class_col_vector) +
  my_theme +
  labs(x= expression('Obs. '*CH[4]*' Flux (nmol m'^{-2}*' s'^{-1}*')'), y = expression('Pred. '*CH[4]*' Flux (nmol m'^{-2}*' s'^{-1}*')'))
ggsave("output/predictions/cv/sitemean_pvo_log10.png",
       width = 13, height = 24, units = c("cm"), dpi = 300)

# by Climate/class
ungroup(rf_pred_all) %>% 
  # group_by(ID, Year) %>% 
  group_by(ID, Year) %>% 
  summarize(MeanO = mean(FCH4, na.rm=TRUE),
            MeanP = mean(FCH4P, na.rm=TRUE),
            MedO = median(FCH4, na.rm=TRUE),
            MedP = median(FCH4P, na.rm=TRUE),
            Class = Class[1],
            Climate = Climate[1]) %>% 
  ggplot(aes(MeanO, MeanP, col = Class)) +
  # scale_x_log10(limits = c(3,600)) +
  # scale_y_log10(limits = c(3,600)) +
  geom_point(size = 3, alpha = 0.85) +
  geom_abline(slope = 1, intercept = 0, colour = 'grey') +
  scale_color_manual(values = class_col_vector) +
  facet_wrap(~Climate, scales = 'free', ncol = 1) +
  my_theme +
  labs(x= expression('Obs. '*CH[4]*' Flux (nmol m'^{-2}*' s'^{-1}*')'), y = expression('Pred. '*CH[4]*' Flux (nmol m'^{-2}*' s'^{-1}*')'))
ggsave("output/predictions/cv/sitemean_pvo_climate.png",
       width = 13, height = 24, units = c("cm"), dpi = 300)
```

Mean Seasonal Cycles:

```{r msc-plots}
# by-ID
msc <- ungroup(rf_pred_all) %>% 
    # filter(!ID == "USOWC") %>% 
  group_by(ID, Month) %>%
  summarize(MeanO = mean(FCH4, na.rm=TRUE),
            MeanP = mean(FCH4P, na.rm=TRUE),
            MedO = median(FCH4, na.rm=TRUE),
            MedP = median(FCH4P, na.rm=TRUE),
            IGBP = IGBP[1],
            Class = NA) %>%  
  ungroup() %>% 
  summarize(Name = "msc global",
            Samples = n(),
            R2 = cor(MeanP, MeanO)^2,
            NSE = 1 - sum((MeanO - MeanP)^2) / sum((MeanO - mean(MeanO))^2),
            MAE = sum(abs(MeanO - MeanP))/n(),
            nMAE = MAE/sd(MeanO),
            MeanFCH4 = mean(MeanO),
            MedFCH4 = median(MeanO),
            sdFCH4 = sd(MeanO),
            MeanFCH4P = mean(MeanP),
            MedFCH4P = median(MeanP),
            sdFCH4P = sd(MeanP),
            nSD = sdFCH4P/sdFCH4,
            Bias = mean(MeanP - MeanO),
            Class = NA) %>% 
  ungroup() %>% 
  mutate(cBias = abs(Bias)/sum(abs(Bias))*100)

# by-ID, grouped by Class 
msc_class <- ungroup(rf_pred_all) %>% 
    # filter(!ID == "USOWC") %>% 
  group_by(ID, Month) %>%
  summarize(MeanO = mean(FCH4, na.rm=TRUE),
            MeanP = mean(FCH4P, na.rm=TRUE),
            MedO = median(FCH4, na.rm=TRUE),
            MedP = median(FCH4P, na.rm=TRUE),
            Class = Class[1]) %>%  
  ungroup() %>% 
  group_by(Class) %>% 
  summarize(Name = "msc class",
            Samples = n(),
            R2 = cor(MeanP, MeanO)^2,
            NSE = 1 - sum((MeanO - MeanP)^2) / sum((MeanO - mean(MeanO))^2),
            MAE = sum(abs(MeanO - MeanP))/n(),
            nMAE = MAE/sd(MeanO),
            MeanFCH4 = mean(MeanO),
            MedFCH4 = median(MeanO),
            sdFCH4 = sd(MeanO),
            MeanFCH4P = mean(MeanP),
            MedFCH4P = median(MeanP),
            sdFCH4P = sd(MeanP),
            nSD = sdFCH4P/sdFCH4,
            Bias = mean(MeanP - MeanO)) %>% 
  ungroup() %>% 
  mutate(cBias = abs(Bias)/sum(abs(Bias))*100) 

# by-ID, grouped by Climate 
msc_climate <- ungroup(rf_pred_all) %>% 
  # filter(!ID == "USOWC") %>% 
  group_by(ID, Month) %>%
  summarize(MeanO = mean(FCH4, na.rm=TRUE),
            MeanP = mean(FCH4P, na.rm=TRUE),
            MedO = median(FCH4, na.rm=TRUE),
            MedP = median(FCH4P, na.rm=TRUE),
            Climate = Climate[1], 
            Class = NA) %>%  
  ungroup() %>% 
  group_by(Climate) %>% 
  summarize(Name = "msc climate",
            Samples = n(),
            R2 = cor(MeanP, MeanO)^2,
            NSE = 1 - sum((MeanO - MeanP)^2) / sum((MeanO - mean(MeanO))^2),
            MAE = sum(abs(MeanO - MeanP))/n(),
            nMAE = MAE/sd(MeanO),
            MeanFCH4 = mean(MeanO),
            MedFCH4 = median(MeanO),
            sdFCH4 = sd(MeanO),
            MeanFCH4P = mean(MeanP),
            MedFCH4P = median(MeanP),
            sdFCH4P = sd(MeanP),
            nSD = sdFCH4P/sdFCH4,
            Bias = mean(MeanP - MeanO),
            Class = NA) %>% 
  ungroup() %>% 
  mutate(cBias = abs(Bias)/sum(abs(Bias))*100) 

# metrics (by-site for component)
msc_id <- ungroup(rf_pred_all) %>% 
    # filter(!ID == "USOWC") %>% 
  group_by(ID, Month) %>%
  summarize(MeanO = mean(FCH4, na.rm=TRUE),
            MeanP = mean(FCH4P, na.rm=TRUE),
            MedO = median(FCH4, na.rm=TRUE),
            MedP = median(FCH4P, na.rm=TRUE),
            Climate = Climate[1], 
            Class = Class[1]) %>%  
  ungroup() %>% 
  group_by(ID) %>% 
  summarize(Name = "msc ID",
            Samples = n(),
            R2 = cor(MeanP, MeanO)^2,
            NSE = 1 - sum((MeanO - MeanP)^2) / sum((MeanO - mean(MeanO))^2),
            MAE = sum(abs(MeanO - MeanP))/n(),
            nMAE = MAE/sd(MeanO),
            MeanFCH4 = mean(MeanO),
            MedFCH4 = median(MeanO),
            sdFCH4 = sd(MeanO),
            MeanFCH4P = mean(MeanP),
            MedFCH4P = median(MeanP),
            sdFCH4P = sd(MeanP),
            nSD = sdFCH4P/sdFCH4,
            Bias = mean(MeanP - MeanO),
            Class = Class[1]) %>% 
  ungroup() %>% 
  mutate(cBias = abs(Bias)/sum(abs(Bias))*100) 

# join msc
msc_data <- bind_rows(msc, msc_class, msc_climate, msc_id)
write_csv(msc_data, "output/predictions/cv/msc.csv")

### WITHOUT US-OWC
# by-ID
msc <- ungroup(rf_pred_all) %>% 
    filter(!ID == "USOWC") %>%
  group_by(ID, Month) %>%
  summarize(MeanO = mean(FCH4, na.rm=TRUE),
            MeanP = mean(FCH4P, na.rm=TRUE),
            MedO = median(FCH4, na.rm=TRUE),
            MedP = median(FCH4P, na.rm=TRUE),
            IGBP = IGBP[1],
            Class = NA) %>%  
  ungroup() %>% 
  summarize(Name = "msc global",
            Samples = n(),
            R2 = cor(MeanP, MeanO)^2,
            NSE = 1 - sum((MeanO - MeanP)^2) / sum((MeanO - mean(MeanO))^2),
            MAE = sum(abs(MeanO - MeanP))/n(),
            nMAE = MAE/sd(MeanO),
            MeanFCH4 = mean(MeanO),
            MedFCH4 = median(MeanO),
            sdFCH4 = sd(MeanO),
            MeanFCH4P = mean(MeanP),
            MedFCH4P = median(MeanP),
            sdFCH4P = sd(MeanP),
            nSD = sdFCH4P/sdFCH4,
            Bias = mean(MeanP - MeanO),
            Class = NA) %>% 
  ungroup() %>% 
  mutate(cBias = abs(Bias)/sum(abs(Bias))*100)

# by-ID, grouped by Class 
msc_class <- ungroup(rf_pred_all) %>% 
      filter(!ID == "USOWC") %>%
  group_by(ID, Month) %>%
  summarize(MeanO = mean(FCH4, na.rm=TRUE),
            MeanP = mean(FCH4P, na.rm=TRUE),
            MedO = median(FCH4, na.rm=TRUE),
            MedP = median(FCH4P, na.rm=TRUE),
            Class = Class[1]) %>%  
  ungroup() %>% 
  group_by(Class) %>% 
  summarize(Name = "msc class",
            Samples = n(),
            R2 = cor(MeanP, MeanO)^2,
            NSE = 1 - sum((MeanO - MeanP)^2) / sum((MeanO - mean(MeanO))^2),
            MAE = sum(abs(MeanO - MeanP))/n(),
            nMAE = MAE/sd(MeanO),
            MeanFCH4 = mean(MeanO),
            MedFCH4 = median(MeanO),
            sdFCH4 = sd(MeanO),
            MeanFCH4P = mean(MeanP),
            MedFCH4P = median(MeanP),
            sdFCH4P = sd(MeanP),
            nSD = sdFCH4P/sdFCH4,
            Bias = mean(MeanP - MeanO)) %>% 
  ungroup() %>% 
  mutate(cBias = abs(Bias)/sum(abs(Bias))*100) 

# by-ID, grouped by Climate 
msc_climate <- ungroup(rf_pred_all) %>% 
    filter(!ID == "USOWC") %>%
  group_by(ID, Month) %>%
  summarize(MeanO = mean(FCH4, na.rm=TRUE),
            MeanP = mean(FCH4P, na.rm=TRUE),
            MedO = median(FCH4, na.rm=TRUE),
            MedP = median(FCH4P, na.rm=TRUE),
            Climate = Climate[1], 
            Class = NA) %>%  
  ungroup() %>% 
  group_by(Climate) %>% 
  summarize(Name = "msc climate",
            Samples = n(),
            R2 = cor(MeanP, MeanO)^2,
            NSE = 1 - sum((MeanO - MeanP)^2) / sum((MeanO - mean(MeanO))^2),
            MAE = sum(abs(MeanO - MeanP))/n(),
            nMAE = MAE/sd(MeanO),
            MeanFCH4 = mean(MeanO),
            MedFCH4 = median(MeanO),
            sdFCH4 = sd(MeanO),
            MeanFCH4P = mean(MeanP),
            MedFCH4P = median(MeanP),
            sdFCH4P = sd(MeanP),
            nSD = sdFCH4P/sdFCH4,
            Bias = mean(MeanP - MeanO),
            Class = NA) %>% 
  ungroup() %>% 
  mutate(cBias = abs(Bias)/sum(abs(Bias))*100) 

# metrics (by-site for component)
msc_id <- ungroup(rf_pred_all) %>% 
      filter(!ID == "USOWC") %>%
  group_by(ID, Month) %>%
  summarize(MeanO = mean(FCH4, na.rm=TRUE),
            MeanP = mean(FCH4P, na.rm=TRUE),
            MedO = median(FCH4, na.rm=TRUE),
            MedP = median(FCH4P, na.rm=TRUE),
            Climate = Climate[1], 
            Class = Class[1]) %>%  
  ungroup() %>% 
  group_by(ID) %>% 
  summarize(Name = "msc ID",
            Samples = n(),
            R2 = cor(MeanP, MeanO)^2,
            NSE = 1 - sum((MeanO - MeanP)^2) / sum((MeanO - mean(MeanO))^2),
            MAE = sum(abs(MeanO - MeanP))/n(),
            nMAE = MAE/sd(MeanO),
            MeanFCH4 = mean(MeanO),
            MedFCH4 = median(MeanO),
            sdFCH4 = sd(MeanO),
            MeanFCH4P = mean(MeanP),
            MedFCH4P = median(MeanP),
            sdFCH4P = sd(MeanP),
            nSD = sdFCH4P/sdFCH4,
            Bias = mean(MeanP - MeanO),
            Class = Class[1]) %>% 
  ungroup() %>% 
  mutate(cBias = abs(Bias)/sum(abs(Bias))*100) 

# join msc
msc_data <- bind_rows(msc, msc_class, msc_climate, msc_id)
write_csv(msc_data, "output/predictions/cv/msc_wo_usosc.csv")
```

Other MSC plots:

```{r other-msc-plots}

# plot histogram of msc performance: R2
msc_data %>% 
  filter(Name == "msc ID",
         NSE > 0) %>% 
  dplyr::select(ID, Class, R2, NSE, MAE, nMAE, Bias, cBias) %>% 
  gather(key = "Metric", value = "Score", 3:8) %>% 
  filter(Metric %in% c("R2", "NSE")) %>% 
  ggplot(aes(Score, fill = Class)) +
  geom_histogram(bins = 15) +
  facet_wrap(~Metric, ncol = 1) +
  scale_fill_manual(values = rep(class_col_vector,8)) +
  my_theme
ggsave("output/predictions/cv/msc_histogram_r2.png",
       width = 13, height = 24, units = c("cm"), dpi = 300)


# plot histogram of msc performance: BIAS
msc_data %>% 
  filter(Name == "msc ID") %>% 
  dplyr::select(ID, Class, R2, NSE, MAE, nMAE, Bias, cBias) %>% 
  gather(key = "Metric", value = "Score", 3:8) %>% 
  filter(Metric %in% c("Bias", "cBias")) %>% 
  ggplot(aes(Score, fill = Class)) +
  geom_histogram() +
  facet_wrap(~Metric, scales = 'free', ncol = 1) +
  scale_fill_manual(values = rep(class_col_vector,8)) +
  my_theme
ggsave("output/predictions/cv/msc_histogram_bias.png",
       width = 13, height = 24, units = c("cm"), dpi = 300)


# plot histogram of msc performance: MAE
msc_data %>% 
  filter(Name == "msc ID") %>% 
  dplyr::select(ID, Class,R2, NSE, MAE, nMAE, Bias, cBias) %>% 
  gather(key = "Metric", value = "Score", 3:8) %>% 
  filter(Metric %in% c("MAE", "nMAE")) %>% 
  ggplot(aes(Score, fill = Class)) +
  geom_histogram() +
  facet_wrap(~Metric, scales = 'free', ncol = 1) +
  scale_fill_manual(values = rep(class_col_vector,8)) +
  my_theme
ggsave("output/predictions/cv/msc_histogram_mae.png",
       width = 13, height = 24, units = c("cm"), dpi = 300)

# global msc comparison
ungroup(rf_pred_all) %>% 
  group_by(ID) %>%
  mutate(annual_meanO = mean(FCH4, na.rm=TRUE),
         annual_meanP = mean(FCH4P, na.rm=TRUE)) %>% 
  group_by(ID, Month) %>% 
  summarize(annual_meanO = annual_meanO[1],
            annual_meanP = annual_meanP[1],
            mscO = abs(mean(FCH4, na.rm=TRUE)-annual_meanO),
            mscP = abs(mean(FCH4P, na.rm=TRUE)-annual_meanP),
            IGBP = IGBP[1],
            Climate = Climate[1],
            Class = Class[1],
            Months = n()) %>% 
  ungroup() %>% 
  ggplot(aes(mscO, mscP, col = Class)) +
  # scale_x_log10(limits = c(3,600)) +
  # scale_y_log10(limits = c(3,600)) +
  geom_point(size = 3, alpha = 0.6) +
  geom_abline(slope = 1, intercept = 0, colour = 'grey') +
  scale_color_manual(values = class_col_vector) +
  my_theme +
  labs(x= expression('Obs. '*CH[4]*' Flux (nmol m'^{-2}*' s'^{-1}*')'), y = expression('Pred. '*CH[4]*' Flux (nmol m'^{-2}*' s'^{-1}*')'))
ggsave("output/predictions/cv/msc_pvo.png",
       width = 13, height = 24, units = c("cm"), dpi = 300)

# MSC plots Climate
ungroup(rf_pred_all) %>% 
  group_by(ID) %>%
  mutate(annual_meanO = mean(FCH4, na.rm=TRUE),
         annual_meanP = mean(FCH4P, na.rm=TRUE)) %>% 
  group_by(ID, Month) %>% 
  summarize(annual_meanO = annual_meanO[1],
            annual_meanP = annual_meanP[1],
            mscO = abs(mean(FCH4, na.rm=TRUE)-annual_meanO),
            mscP = abs(mean(FCH4P, na.rm=TRUE)-annual_meanP),
            IGBP = IGBP[1],
            Climate = Climate[1],
            Class = Class[1],
            Months = n()) %>% 
  ungroup() %>% 
  ggplot(aes(mscO, mscP, col = Class)) +
  geom_abline(slope = 1, intercept = 0, colour = 'black') +
  geom_point(size = 2) +
  facet_wrap(~Climate, ncol = 2, scales = 'free') +
  scale_color_manual(values = class_col_vector) +
  my_theme +
  labs(x= expression("Observed "*CH[4]*' MSC (nmol m'^{-2}*' s'^{-1}*')'), y = expression("Predicted "*CH[4]*' MSC (nmol m'^{-2}*' s'^{-1}*')')) 
ggsave("output/predictions/cv/msc_pvo_climate.png",
       width = 13, height = 24, units = c("cm"), dpi = 300)


## FINAL FIGURE 
# MSC plots ID
climate_names <- c(`1` = "Tundra", `2` = "Boreal", `3` = "Temperate", `4` = "Tropical")

ungroup(rf_pred_all) %>% 
  filter(!ID == "USOWC") %>%
  mutate(Climate_letter = ifelse(Climate == 1, "(a)", NA),
         Climate_letter = ifelse(Climate == 2, "(b)", Climate_letter),
         Climate_letter = ifelse(Climate == 3, "(c)", Climate_letter),
         Climate_letter = ifelse(Climate == 4, "(d)", Climate_letter)) %>% 
  mutate(`Site ID` = paste0(Climate_letter, " ",substr(ID, 1, 2), "-", substr(ID, 3, 5))) %>% 
  group_by(`Site ID`) %>%
  mutate(annual_meanO = mean(FCH4, na.rm=TRUE),
         annual_meanP = mean(FCH4P, na.rm=TRUE)) %>% 
  group_by(`Site ID`, Month) %>% 
  summarize(annual_meanO = annual_meanO[1],
            annual_meanP = annual_meanP[1],
            mscO = abs(mean(FCH4, na.rm=TRUE)-annual_meanO),
            mscP = abs(mean(FCH4P, na.rm=TRUE)-annual_meanP),
            IGBP = IGBP[1],
            Climate = Climate[1],
            Months = n()) %>% 
  ungroup() %>% 
  ggplot(aes(mscO, mscP, col = `Site ID`, shape = `Site ID`, fill = `Site ID`)) +
  geom_line(stat = "smooth", method = 'lm', se = FALSE, size = 1.2, alpha = 0.9, lineend = "round") +
  geom_point(size = 2.5, alpha = 0.8) +
  geom_abline(slope = 1, intercept = 0, colour = 'black', linetype = 2) +
  facet_wrap(~Climate, ncol = 2, scales = 'free', labeller = labeller(Climate = climate_names)) +
  scale_y_continuous(limits = c(0,200)) +
  scale_x_continuous(limits = c(0,200)) +
  scale_color_manual(values = rep(col_vector_values,2)) +
  scale_fill_manual(values = rep(col_vector_values,2)) +
  scale_shape_manual(values = rep(15:25,4)) +
  theme(legend.position = "right",
        legend.direction = 'vertical') +
  my_theme +
  labs(x= expression("Observed "*CH[4]*' MSC (nmol m'^{-2}*' s'^{-1}*')'), y = expression("Predicted "*CH[4]*' MSC (nmol m'^{-2}*' s'^{-1}*')')) 
ggsave("output/predictions/cv/msc_pvo_id.png",
       width = 13, height = 24, units = c("cm"), dpi = 300)
```

Timeseries plots:

```{r timeseries-plots}
# timeseries
ungroup(rf_pred_all) %>% 
  group_by(ID) %>%
  mutate(annual_meanO = mean(FCH4, na.rm=TRUE),
         annual_meanP = mean(FCH4P, na.rm=TRUE)) %>% 
  group_by(ID, Month) %>% 
  summarize(annual_meanO = annual_meanO[1],
            annual_meanP = annual_meanP[1],
            mscO = mean(FCH4, na.rm=TRUE)-annual_meanO,
            mscP = mean(FCH4P, na.rm=TRUE)-annual_meanP,
            IGBP = IGBP[1],
            Months = n()) %>% 
  ggplot(aes(Month, mscO)) +
  geom_point(size = 3) +
  geom_point(aes(Month, mscP), col = 'orange', size = 3) +
  facet_wrap(~ID,scales = 'free',ncol=8) +
  # scale_y_log10(limits = c(0.01,1000), breaks = c(0.001,0.1,10,1000), labels = c(0.001,0.1,10,1000)) +
  scale_x_continuous(breaks = c(1:12), limits = c(1,12), labels = c("J","F","M","A","M","J","J","A","S","O","N","D")) +
  my_theme +
  labs(x= "Month", y = expression(CH[4]*' Flux (nmol m'^{-2}*' s'^{-1}*')')) 
ggsave("output/predictions/cv/msc_timeseries.png",
       width = 13, height = 24, units = c("cm"), dpi = 300)

## FINAL FIGURE
# timeseries
ungroup(rf_pred_all) %>% 
  filter(ID %in% c("SEDeg", "DEHte","BWNxr", "FRLGt", "USORv", "NZKop")) %>% 
  group_by(ID) %>%
  mutate(annual_meanO = mean(FCH4, na.rm=TRUE),
         annual_meanP = mean(FCH4P, na.rm=TRUE)) %>% 
  group_by(ID, Month) %>% 
  summarize(annual_meanO = annual_meanO[1],
            annual_meanP = annual_meanP[1],
            mscO = mean(FCH4, na.rm=TRUE)-annual_meanO,
            mscP = mean(FCH4P, na.rm=TRUE)-annual_meanP,
            IGBP = IGBP[1],
            Climate = Climate[1],
            Months = n()) %>% 
  ggplot(aes(Month, mscO)) +
  geom_point(size = 2) +
  geom_point(aes(Month, mscP), col = 'orange', size = 2) +
  facet_wrap(~ID, scales = 'free', ncol=3, labeller = labeller(Climate = climate_names)) +
  # scale_y_log10(limits = c(0.01,1000), breaks = c(0.001,0.1,10,1000), labels = c(0.001,0.1,10,1000)) +
  scale_x_continuous(breaks = c(1:12), limits = c(1,12), labels = c("J","F","M","A","M","J","J","A","S","O","N","D")) +
  my_theme +
  labs(x= "Month", y = expression(CH[4]*' Flux (nmol m'^{-2}*' s'^{-1}*')')) 
ggsave("output/predictions/cv/msc_highlowlights.png",
       width = 20, height = 24, units = c("cm"), dpi = 300)
```

Look at JP-BBY hysteresis. (Ueyama et al. 2020; Chang et al. 2021)

```{r jp-bby-hysteresis}
head(rf_pred_all)
rf_pred_all %>% 
  filter(ID == "JPBBY",
         Year %in% c(2015, 2016, 2017)) %>% 
  dplyr::select(ID, Year, Week, FCH4, FCH4P, TA, TA_LAG2) %>% 
  pivot_longer(
    4:5,
    names_to = "data",
    values_to = "ch4_flux"
  ) %>% 
  ggplot(aes(TA, ch4_flux, color = Week)) +
    geom_point(size = 3) +
  facet_wrap(~Year+data, ncol = 2) +
  labs(x = expression("Air Temperature ("*degree*"C)"),
       y = expression(CH[4]*" Flux (nmol m"^{-2}*" s"^{-1}*")")) +
  scale_color_gradient2(low = "red", mid = "white", high = "blue", midpoint = 30) +
  my_theme
ggsave("output/predictions/cv/hysteresis.png",
      height = 30, width = 20, units = c("cm"), dpi = 300)
```

Look at all site hysteresis:

```{r all-site-hysteresis}
head(rf_pred_all)
rf_pred_all %>% 
  filter(TA > 0) %>% 
  dplyr::select(ID, Year, Week, FCH4, FCH4P, TA, TA_LAG2) %>% 
  pivot_longer(
    4:5,
    names_to = "data",
    values_to = "ch4_flux"
  ) %>% 
  group_by(ID, Year) %>% 
  mutate(warm_cool = ifelse(Week < 30, "warming", "cooling")) %>% 
  ggplot(aes(TA, ch4_flux, color = Week)) +
    geom_point(size = 1) +
  geom_smooth(color = "black", se = TRUE) +
  facet_wrap(~data+warm_cool, ncol = 2) +
  my_theme
```

Anomalies (i.e., excursions from mean seasonal cycle)

```{r anomalies}
# first create mean seasonal cycle dataframe
pred.msc <- ungroup(rf_pred_all) %>% 
  group_by(ID, Month) %>% 
  summarize(mscO = mean(FCH4, na.rm=TRUE),
            mscP = mean(FCH4P, na.rm=TRUE),
            Years = n()) 

# then left join back onto full dataframe
rf.pred.msc <- rf_pred_all %>% left_join(pred.msc, by = c("ID","Month")) 

# global monthly anomaly summary
anomaly <- ungroup(rf.pred.msc) %>% 
  group_by(ID, Year, Month) %>%
  summarize(mscO = mscO[1],
            Years = Years[1],
            FCH4 = mean(FCH4),
            FCH4P = mean(FCH4P)) %>% 
  mutate(anomalyO = FCH4 - mscO,
         anomalyP = FCH4P - mscO) %>% 
  ungroup() %>% 
  summarize(Name = "anomaly",
            Samples = n(),
            R2 = cor(anomalyP, anomalyO)^2,
            NSE = 1 - sum((anomalyO - anomalyP)^2) / sum((anomalyO - mean(anomalyO))^2),
            MAE = sum(abs(anomalyO - anomalyP))/n(),
            nMAE = MAE/sd(anomalyO),
            MeanFCH4 = mean(anomalyO),
            MedFCH4 = median(anomalyO),
            sdFCH4 = sd(anomalyO),
            MeanFCH4P = mean(anomalyP),
            MedFCH4P = median(anomalyP),
            sdFCH4P = sd(anomalyP),
            nSD = sdFCH4P/sdFCH4,
            Bias = mean(anomalyP - anomalyO)) %>% 
  ungroup() %>% 
  mutate(cBias = abs(Bias)/sum(abs(Bias))*100)

# by-ID, grouped by CLASS 
anomaly_class <- ungroup(rf.pred.msc) %>% 
  group_by(ID, Year, Month) %>%
  summarize(mscO = mscO[1],
            Years = Years[1],
            FCH4 = mean(FCH4),
            FCH4P = mean(FCH4P),
            Class = Class[1]) %>% 
  mutate(anomalyO = FCH4 - mscO,
         anomalyP = FCH4P - mscO) %>% 
  ungroup() %>% 
  group_by(Class) %>% 
  summarize(Name = "Class",
            Samples = n(),
            R2 = cor(anomalyP, anomalyO)^2,
            NSE = 1 - sum((anomalyO - anomalyP)^2) / sum((anomalyO - mean(anomalyO))^2),
            MAE = sum(abs(anomalyO - anomalyP))/n(),
            nMAE = MAE/sd(anomalyO),
            MeanFCH4 = mean(anomalyO),
            MedFCH4 = median(anomalyO),
            sdFCH4 = sd(anomalyO),
            MeanFCH4P = mean(anomalyP),
            MedFCH4P = median(anomalyP),
            sdFCH4P = sd(anomalyP),
            nSD = sdFCH4P/sdFCH4,
            Bias = mean(anomalyP - anomalyO)) %>% 
  ungroup() %>% 
  mutate(cBias = abs(Bias)/sum(abs(Bias))*100)

# by-ID, grouped by Climate 
anomaly_climate <- ungroup(rf.pred.msc) %>% 
  group_by(ID, Year, Month) %>%
  summarize(mscO = mscO[1],
            Years = Years[1],
            FCH4 = mean(FCH4),
            FCH4P = mean(FCH4P),
            Climate = Climate[1]) %>% 
  mutate(anomalyO = FCH4 - mscO,
         anomalyP = FCH4P - mscO) %>% 
  ungroup() %>% 
  group_by(Climate) %>% 
  summarize(Name = "Climate",
            Samples = n(),
            R2 = cor(anomalyP, anomalyO)^2,
            NSE = 1 - sum((anomalyO - anomalyP)^2) / sum((anomalyO - mean(anomalyO))^2),
            MAE = sum(abs(anomalyO - anomalyP))/n(),
            nMAE = MAE/sd(anomalyO),
            MeanFCH4 = mean(anomalyO),
            MedFCH4 = median(anomalyO),
            sdFCH4 = sd(anomalyO),
            MeanFCH4P = mean(anomalyP),
            MedFCH4P = median(anomalyP),
            sdFCH4P = sd(anomalyP),
            nSD = sdFCH4P/sdFCH4,
            Bias = mean(anomalyP - anomalyO)) %>% 
  ungroup() %>% 
  mutate(cBias = abs(Bias)/sum(abs(Bias))*100)

# now group by ID
anomaly_id <- ungroup(rf.pred.msc) %>% 
  group_by(ID, Year, Month) %>%
  summarize(mscO = mscO[1],
            Years = Years[1],
            FCH4 = mean(FCH4),
            FCH4P = mean(FCH4P),
            Climate = Climate[1]) %>% 
  mutate(anomalyO = FCH4 - mscO,
         anomalyP = FCH4P - mscO) %>% 
  ungroup() %>% 
  group_by(ID) %>% 
  summarize(Name = "ID",
            Samples = n(),
            R2 = cor(anomalyP, anomalyO)^2,
            NSE = 1 - sum((anomalyO - anomalyP)^2) / sum((anomalyO - mean(anomalyO))^2),
            MAE = sum(abs(anomalyO - anomalyP))/n(),
            nMAE = MAE/sd(anomalyO),
            MeanFCH4 = mean(anomalyO),
            MedFCH4 = median(anomalyO),
            sdFCH4 = sd(anomalyO),
            MeanFCH4P = mean(anomalyP),
            MedFCH4P = median(anomalyP),
            sdFCH4P = sd(anomalyP),
            nSD = sdFCH4P/sdFCH4,
            Bias = mean(anomalyP - anomalyO)) %>% 
  ungroup() %>% 
  mutate(cBias = abs(Bias)/sum(abs(Bias))*100)

# join anomalies
anomaly_data <- bind_rows(anomaly, anomaly_class, anomaly_climate, anomaly_id)
write_csv(anomaly_data, "output/predictions/cv/anomaly.csv")

# global anomalies 
rf.pred.msc %>% 
  group_by(ID, Year, Month) %>% 
  summarize(mscO = mscO[1],
            mscP = mscP[1],
            Years = Years[1],
            FCH4 = FCH4[1],
            FCH4P = FCH4P[1],
            Class = Class[1],
            Climate = Climate[1]) %>% 
  mutate(anomalyO = abs(FCH4 - mscO),
         anomalyP = abs(FCH4P - mscP)) %>%  
  ungroup() %>% 
  ggplot(aes(anomalyO, anomalyP, col = Class)) +
  # scale_x_log10(limits = c(0.01,1000)) +
  # scale_y_log10(limits = c(0.01,1000)) +
  geom_point(size = 2, alpha = 0.5) +
  geom_abline(slope = 1, intercept = 0, colour = 'grey') +
  scale_color_manual(values = class_col_vector) +
  # facet_wrap(~Climate, scales = 'free', ncol = 1) +
  my_theme +
  labs(x= expression('Obs. '*CH[4]*' Flux (nmol m'^{-2}*' s'^{-1}*')'), y = expression('Pred. '*CH[4]*' Flux (nmol m'^{-2}*' s'^{-1}*')'))
ggsave("output/predictions/cv/anomalies_pvo.png",
       width = 20, height = 10, units = c("cm"), dpi = 300)

# now calculate monthly anomalies  
rf.pred.msc %>% 
  group_by(ID, Year, Month) %>% 
  summarize(mscO = mscO[1],
            mscP = mscP[1],
            Years = Years[1],
            FCH4 = FCH4[1],
            FCH4P = FCH4P[1],
            Class = Class[1],
            Climate = Climate[1]) %>% 
  mutate(anomalyO = abs(FCH4 - mscO),
         anomalyP = abs(FCH4P - mscP)) %>%  
  ungroup() %>% 
  ggplot(aes(anomalyO, anomalyP, col = Class)) +
  # scale_x_log10(limits = c(0.01,1000)) +
  # scale_y_log10(limits = c(0.01,1000)) +
  geom_point(size = 2, alpha = 0.5) +
  geom_abline(slope = 1, intercept = 0, colour = 'grey') +
  scale_color_manual(values = class_col_vector) +
  facet_wrap(~Climate, scales = 'free', ncol = 1) +
  my_theme +
  labs(x= expression('Obs. '*CH[4]*' Flux (nmol m'^{-2}*' s'^{-1}*')'), y = expression('Pred. '*CH[4]*' Flux (nmol m'^{-2}*' s'^{-1}*')'))
ggsave("output/predictions/cv/anomalies_pvo_climate.png",
       width = 13, height = 36, units = c("cm"), dpi = 300)

# timeseries
rf.pred.msc %>% 
  group_by(ID, Year, Month) %>% 
  summarize(mscO = mscO[1],
            mscP = mscP[1],
            Years = Years[1],
            FCH4 = FCH4[1],
            FCH4P = FCH4P[1],
            Class = Class[1],
            Climate = Climate[1]) %>% 
  mutate(anomalyO = abs(FCH4 - mscO),
         anomalyP = abs(FCH4P - mscP)) %>%  
  ungroup() %>% 
  ggplot(aes(Month, anomalyO)) +
    geom_point(col = 'black', size = 3) +
    geom_point(aes(Month, anomalyP), col = 'orange', size = 3, alpha = 0.5) +
    facet_wrap(~ID, scales = 'free', ncol = 8) +
    # scale_y_log10(limits = c(0.01,1000), breaks = c(0.001,0.1,10,1000), labels = c(0.001,0.1,10,1000)) +
    scale_x_continuous(breaks = c(1:12), limits = c(1,12), labels = c("J","F","M","A","M","J","J","A","S","O","N","D")) +
    my_theme +
    labs(x= "Month", y = expression(CH[4]*' Flux (nmol m'^{-2}*' s'^{-1}*')')) 
ggsave("output/predictions/cv/anomalies_timeseries.png",
       width = 45, height = 25, units = c("cm"), dpi = 300)
```

## 3. Variable Importance

Generate rankings with VarImp:

```{r var-imp-rankings}
# read rf model
rf_model <- readRDS("output/ensembles/cv/best-feat.rds")

# get folds
folds <- length(rf_model)

## look at variable importance, create table of all site rankings
variable.imp <- list()
var.imp.ranks <- list()
variable.imp.single <- list()
for (i in 1:folds) {
  variable.imp[[i]] <- varImp(rf_model[[i]], scale = FALSE)
}
var.imp.names <- rownames(variable.imp[[1]]$importance)

for (i in 1:folds) {
  var.imp.ranks[[i]] <- variable.imp[[i]]$importance$Overall
  variable.imp.single[[i]] <- cbind(var.imp.names, var.imp.ranks[[i]])
  variable.imp.single[[i]] <- variable.imp.single[[i]] %>% as_tibble() %>% mutate(V2 = as.integer(V2))
  variable.imp.single[[i]] <- variable.imp.single[[i]] %>% arrange(desc(V2)) %>% dplyr::select(var.imp.names,V2)
}

for (i in 1:folds) {
  names(variable.imp.single[[i]]) <- c("Var",paste("Imp",i,sep=""))
  variable.imp.single[[i]] <- variable.imp.single[[i]] %>% arrange(Var)
}

# get full table of rf pred impotance 
variable.importance <- as_tibble(bind_cols(variable.imp.single)) %>% 
  dplyr::select(1,2,4,6,8,10,12,14,16,18,20,22,24,26,28,30,
                32,34,36,38,40,42,44,46,48,50,52) %>% group_by(Var...1) %>% 
  mutate(AvgImp = mean(c(Imp1,Imp2,Imp3,Imp4,Imp5,Imp6,Imp7,Imp8,Imp9,Imp10,
                         Imp11,Imp12,Imp13,Imp14,Imp15,Imp16,Imp17,Imp18,
                         Imp19,Imp20,Imp21,Imp22,Imp23,Imp24,Imp25,Imp26))) %>% 
  arrange(desc(AvgImp)) %>% 
  ungroup() %>% 
  mutate(ScaledAvgImp = AvgImp/max(AvgImp))

view(variable.importance)

write_csv(variable.importance,
          "output/varimp/best_feat.csv")

# read in data again
variable.importance <- read.csv("output/varimp/best_feat.csv")

# get effective number of predictors
sum(variable.importance$ScaledAvgImp)

# read in predictor summary
pred.summary <- read_csv("data/predictors_metadata.csv") %>% 
  dplyr::select(Var = Predictor, Information = Content, Class)

# var imp plot
variable.importance %>% 
  rename(Var = Var...1) %>% 
  left_join(pred.summary, by = "Var") %>% 
  mutate(Information = as.character(Information),
         Class = as.character(Class),
         Information = ifelse(is.na(Information), "Spatiotemporal", Information),
         Class = ifelse(is.na(Class), "Biomet", Class),
         Class = ifelse(Var == "LSWI_LAG2", "Land Cover", Class),
         Var = fct_reorder(Var, ScaledAvgImp)) %>% 
  ggplot(aes(x = Var, y = ScaledAvgImp)) +
    geom_segment(aes(x = Var, xend = Var, y = 0, yend = ScaledAvgImp), color = 'grey', stat = "identity") +
    geom_point(aes(color = Class, shape = Information), size = 4) +
    scale_color_manual(values = c("Turquoise", "Dark Blue", "Dark Green", "Brown","Grey")) +
    # scale_fill_manual(values = c("Light Green", "Dark Grey", "Dark Blue", "Brown", "Dark Green")) +
    scale_shape_manual(values = c(15,16,17)) +
    coord_flip() +
    xlab("Predictor") + ylab("Importance") +
    my_theme +
    theme(legend.position='bottom', legend.box = 'vertical')
ggsave("output/varimp/pred_rank.png",
       width = 18, height = 13, units = c("cm"), dpi = 300)
```

Variable Responses:

```{r var-responses}
# read rf model
rf_model <- readRDS("output/ensembles/cv/best-feat.rds")

# get feature names
variable.importance <- varImp(rf_model[[1]], scale = TRUE)
feat <- rownames(variable.importance$importance) %>% rev()

# Read in full csv
train <- read_csv("output/predictions/cv/best_feat_pred.csv") # local path

# look at all relationships
train %>% 
  # filter(!ID == "USOWC") %>% 
  dplyr::select(FCH4P = FCH4P, FCH4, feat) %>% 
  gather(key = "Predictor", value = "Value", 3:8) %>% 
  ggplot(aes(Value, FCH4)) + 
  geom_point(alpha = 0.05, size = 1) +
  geom_point(aes(Value, FCH4P), alpha = 0.05, size = 1, color = "orange") +
  facet_wrap(~Predictor, scales = 'free') +
  ylab(label =  expression("FCH4 (nmol m"^{-2}*" s"^{-1}*")")) +
  my_theme
ggsave("output/varimp/var_response_all.png",
       width = 25, height = 22, units = c("cm"), dpi = 300)
```


Partial Dependency Plots:

```{r pdp}
# read mc rf model
rf_model <- readRDS("output/ensembles/cv/best-feat.rds")

# Read mc training data csv
train <- read_csv("data/final.csv") # local path

# pdp
ice.TA <- rf_model[[1]] %>% 
  partial(pred.var = c("TA"), 
          train = train, 
          plot.engine = "ggplot2", 
          ice = FALSE, 
          center = TRUE)
plotPartial(ice.TA, colorkey = TRUE) 

```


