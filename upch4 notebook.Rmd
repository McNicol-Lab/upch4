---
title: "FLUXNET-CH4 Upscaling"
author: "Gavin McNicol"
date: "2/22/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Load packages and ggplot theme:

```{r}
library(tidyverse)
library(lubridate)
source("code/ggplot_theme.R")
```

## Workflow

  1. Objective of Study
  2. Input Data
      + FLUXNET-CH4 Data
      + Gridded Data
  3. FLUXNET-CH4 Pre-Processing
      + FLUXNET-CH4 Data Preparation
          - Averaging
          - Variable Selection
      + Subset Wetlands, Dates
      + Cluster Sites for Cross Validation
      + Finalize Data
          - Remove Extraneous
          - Impute Missing Data
          - Add Lagged Data
      + FLUXNET-CH4 Data Quality Control
      + Table of Final FLUXNET-CH4 Inputs
  4. Gridded Data Pre-Processing
      + Grid Preparation
          - MODIS
          - PPFD_IN
          - Temporal (not used)
          - Rpot (not used)
      + Grid Extraction
          - Extract Global Products
              - Canopy Height
              - Computed (not used)
              - Compound Topographic Index
              - Earth Environment
              - N and S Deposition
              - SoilGrids
              - TerraClimate
              - Fractional Vegetation Cover (VCF)
              - Wetland Extent (WAD2M)
              - WorldClim 2.0
          - MODIS Processing
          - Merge Gridded Data
      + Gridded Data Quality Control
  5. Forward Feature Selection (FFS)
      + Filter Weekly Data
      + Feature Subset Experiments
      + FFS
          - First Pair
          - Additional Stepwise Features
          - FFS Evolution Plots
      + Summarize FFS Performance
  6. Cross Validation
      + ML Model Training
          - RF and Final Predictors or Subsets
          - XGB and Final Predictors or Subsets
          - ANN and Final Predictors or Subsets
          - RNN and Final Predictors or Subsets
      + Output Ensembles and Predictions
      + Validation 
          - Global Performance
          - Site-means
          - Monthly Seasonal Cycles
          - Monthly Anomalies
  7. Variable Importances
      + Variable Importance Rankings
      + Variable Responses
      + Partial Dependency Plots
      + ShapR
  8. Upscaled Model with Monte Carlo (MC)
      + Forcing Data
          - Mapping
          - Member Product Choices
          - Evaluate Product Divergence
      + Data Preparation
          - Extract Gridded Data for MC
          - Pre-Process FLUXNET-CH4 for MC
      + MC Simulations
      + MC ML Model Training
      + MC ML Model Validation
  9. Upscaling
      + Prepare Member Forcing Data
      + Run on Computing Cluster
          - Output Grids and Sums
      + Product Evaluation
          - Unweighted Wetland Fluxes (nmol)
          - Weighted Sums and Uncertainties (Tg)
          - Independent Validation
  10. Data Representativeness
      + Prepare Gridded Data
      + Global Dissimilarity
      + Tower Constituency
      + Extrapolation Errors
          - MC ML Model Training - Dissimilarity Only
          
[**Link to Workflow Figure**](https://drive.google.com/drive/folders/1jiFyqzoxxMpdtRLCwxCtzKpfILRNIW5K)
          
$~$            
      
#### 1. Objective of Study 

The goal of `FLUXNET-CH4 Upscaling` is to implement FLUXCOM-like ML approaches (e.g. [Jung et al. 2020](10.5194/bg-17-1343-2020)) to train a machine learning model using eddy covariance data that can predict wetland methane (CH4) fluxes globally. The predictions should be readily comparable to the Global Carbon Project (GCP) bottom-up process model ensembles that inform the Global Methane Budget ([Saunois et al. 2020](10.5194/essd-12-1561-2020)). Wetland fluxes specifically, rather than methane fluxes from all terrestrial ecosystems, are the predictive goal of this study because 1) most eddy covariance data available are in wetlands, with limited coverage across the multitude of upland ecosystems, 2) methane fluxes are highest and most variable in wetlands, and 3) comparable bottom-up process models predict wetland fluxes, then scale predictions to a global grid-cell using a prescribed (diagnostic runs) or model-derived (prognostic runs) wetland extent. In the last GCP Global Methane Budget ([Saunois et al. 2020](10.5194/essd-12-1561-2020)), diagnostic runs used the WAD2M product ([Zhang et al. in review](10.5194/essd-2020-262)). WAD2M includes coastal wetlands, however, we exclude coastal wetlands from the upscaling because they are salt-influenced and we do not have consistent salinity coverage, thus their inclusion is likely to bias flux estimates low even in non-coastal wetlands. The final model will be forced with available globally gridded data. Final product specifications are:

  - Monthly time-step
  - Historic reconstruction: ca. 2000 - 2018
  - 0.25-degree grid cell resolution (as is WAD2M)
  - Propagates training data uncertainties using Monte Carlo simulations
  - Considers sensitivity to global forcing data product choices

$~$    
  
#### 2. Input Data

**FLUXNET-CH4 Data**

The eddy covariance data used in this study are publicly available as part of the FLUXNET-CH4 community product V1.0 at [fluxnet.org](https://fluxnet.org/data/fluxnet-ch4-community-product/). The FLUXNET-CH4 synthesis activity is introduced in [Knox et al. 2019](10.1175/BAMS-D-18-0268.1) along with a detailed description of the eddy covariance post-processing steps including methane flux (FCH4) uncertainties. The first full (V1.0) database release (FLUXNET-CH4, hereafter) is described for 81 sites, and used for a wetland seasonality analysis in [Delwiche et al. in review](10.5194/essd-2020-307). **Data for this analysis were downloaded from fluxnet.org on Feb 22, 2021. [Download Manifest](https://docs.google.com/spreadsheets/d/1--_-XyBqsyiMIdc6JXqhilOOYFLeaY-UTMFhhI4Sd5M/edit#gid=0)**

Links:

  - [FLUXNET-CH4 Site Metadata](https://docs.google.com/spreadsheets/d/1yBJr_Q8Fv_VKxAoVO1M6ZCUAYlS46iAa5FFqQheH3aE/edit#gid=0)
  - Permission was received via email on Feb 22, 2021, to use Tier 2 Data Policy sites in this study (SE-St1 and RU-Vrk; PI Thomas Friborg)
  - Two additional sites (RU-SAM and SE-Sto) were included in the analysis (permission pending), however, were not included in FLUXNET-CH4 V1.0
  - FLUXNET-CH4 data were used both for methane fluxes (FCH4; target variable) and tower-measured bio-meteorological variables (e.g., LE, GPP, TA; predictors)
      + Link to [FLUXNET.org variable descriptions](https://fluxnet.org/data/fluxnet-ch4-community-product/data-variables/)
  
$~$  
  
**Gridded Data (Predictors)**



$~$

#### 3. FLUXNET-CH4 Pre-Processing

**NOTE: This work flow uses many large files so most data is stored locally and requires hard filepaths**
The local file path used for all large files is: `/Volumes/LACIE SHARE/Stanford CH4/upch4_local/`.

##### Set the local head directory:

```{r}
loc <- "/Volumes/LACIE SHARE/Stanford CH4/upch4_local/"
```

##### Local machine steps:

  + Create a copy of FLUXNET-CH4 data and name it `/fluxnet-ch4-data-original`
  + Unzip all site flux files in `/fluxnet-ch4-data` 
  + Reorganize into half-hourly (`/hh`) and `/daily` folders for easy access
  
##### Look at one site of **daily means** data.

```{r}
# setwd(loc)
# files <- list.files("fluxnet-ch4-data/daily/")
# one_site <- read_csv(paste(loc, "fluxnet-ch4-data/daily/", files[1], sep = ""))
# head(one_site)
```

No, but there is a quality flag `_QC`. `1`= data gap shorter than 2 months, `3` = gap exceeds 2 months. 

Issue: **There is also no uncertainty (`_UNC`) estimate on the downloaded daily mean data.**

##### Clean up workspace:

```{r}
# rm(one_site)
```

##### Look at one site of **half-hourly** data.

```{r}
setwd(loc)
files <- list.files("fluxnet-ch4-data/hh/")
one_site <- read_csv(paste(loc, "fluxnet-ch4-data/hh/", files[1], sep = ""))
head(one_site)
```

  - Half-hourly data has `FCH4` uncertainty columns `FCH4_F_RANDUNC` and `FCH4_F_ANNOPTLM_UNC`. Can be averaged over day or week.
  - Missing values are filled with `-9999`

##### Get FLUXNET-CH4 site names:

```{r}
site.names <- paste( substr(files, 5, 6), substr(files, 8, 10), sep = "")
```

##### Get all **half-hourly** flux data: (this will take a few minutes)

```{r echo = F}
hh <- lapply(paste(loc, "fluxnet-ch4-data/hh/", files, sep = ""), read_csv)
names(hh) <- site.names
# str(hh)
```

##### Create a pristine replicate:

```{r}
hh2 <- hh
```

##### Look at all and date columns (to see date and time format):

```{r}
names(hh[[1]])
head(hh[[1]]$TIMESTAMP_END)
```

##### Write and apply function to expand `TIMESTAMP_END` into`Year`, `Month`, `Week`, `Day`, and `DOY` variables to facilitate merging with other data:

```{r}
expand_date <- function(hh_data) {
  hh_data <- hh_data %>% 
  mutate(Year = as.numeric(substr(TIMESTAMP_END, 1, 4)),
         Month = as.numeric(substr(TIMESTAMP_END, 5, 6)),
         Day = as.numeric(substr(TIMESTAMP_END, 7, 8)),
         Date = make_date(Year, Month, Day),
         DOY = yday(Date),
         Week = ceiling(DOY/7),
         Week = ifelse(Week == 53, 52, Week)) %>% 
    group_by(Year, DOY) %>% 
    mutate(HH = 1:n()) %>% 
  dplyr::select(Year, Month, Week, Day, HH, DOY, everything(), - Date, -TIMESTAMP_START, -TIMESTAMP_END)
}

hh <- lapply(hh, expand_date)
hh[[2]] # check it worked
```

##### Check if gap-filled FCH4 `CH4_F_ANNOPTLM` has already been pre-filled with observations `FCH4`, where available.

```{r}
hh[[1]] 
```

FCH4 in row 7 in `hh[[1]]` (ID BRNpw) = 10.71, which **matches** `CH4_F_ANNOPTLM` = 1.071e+01. 
**`CH4_F_ANNOPTLM` has been pre-filled with observations.**

##### Write and apply function to create `imputed`, a flag variable where:

  - `1` == `CH4_F_ANNOPTLM` was imputed
  - `2` == `CH4_F_ANNOPTLM` was observed

```{r}
create_imputed <- function(hh_data) {
  hh_data <- hh_data %>% 
    mutate(imputed = ifelse(FCH4 == -9999, 1, 0))
}

hh <- lapply(hh, create_imputed)
# hh[[1]] check it worked
```

##### Create ID column:

```{r}
for (i in 1:length(hh)){
  hh[[i]] <- hh[[i]] %>%
    mutate(ID = site.names[i]) %>%
    dplyr::select(ID, everything())
}
head(hh[[1]])
```

##### Convert `-9999`- to `NA`:

```{r}
for (i in 1:length(hh)){
  hh[[i]][hh[[i]] == -9999] <- NA
}
head(hh[[1]])
```





